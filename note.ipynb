{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "\n",
    "np.random.seed(13)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame(\n",
    "    {\n",
    "        \"n\": np.random.randn(20),\n",
    "        \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "        \"abool\": np.random.choice([True, False], 20),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Spark Dataframe Basics\n",
    "\n",
    "    - Use the starter code above to create a pandas dataframe.\n",
    "    - Convert the pandas dataframe to a spark dataframe. From this point\n",
    "       forward, do all of your work with the spark dataframe, not the pandas\n",
    "       dataframe.\n",
    "    - Show the first 3 rows of the dataframe.\n",
    "    - Show the first 7 rows of the dataframe.\n",
    "    - What is the difference between `.show` and `.head`?\n",
    "    - View a summary of the data using `.describe`.\n",
    "    - Use `.select` to create a new dataframe with just the `n` and `abool`\n",
    "       columns. View the first 5 rows of this dataframe.\n",
    "    - Use `.select` to create a new dataframe with just the `group` and `abool`\n",
    "       columns. View the first 5 rows of this dataframe.\n",
    "    - Use `.select` to create a new dataframe with the `group` column and the\n",
    "       `abool` column renamed to `a_boolean_value`. Show the first 3 rows of\n",
    "       this dataframe.\n",
    "    - Use `.select` to create a new dataframe with the `group` column and the\n",
    "       `n` column renamed to `a_numeric_value`. Show the first 6 rows of this\n",
    "       dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[n: double, group: string, abool: boolean]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Show the first 3 rows of the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(n=-0.712390662050588, group='z', abool=False),\n",
       " Row(n=0.753766378659703, group='x', abool=False),\n",
       " Row(n=-0.044503078338053455, group='z', abool=False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Show the first 7 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(n=-0.712390662050588, group='z', abool=False),\n",
       " Row(n=0.753766378659703, group='x', abool=False),\n",
       " Row(n=-0.044503078338053455, group='z', abool=False),\n",
       " Row(n=0.45181233874578974, group='y', abool=False),\n",
       " Row(n=1.3451017084510097, group='z', abool=False),\n",
       " Row(n=0.5323378882945463, group='y', abool=False),\n",
       " Row(n=1.3501878997225267, group='z', abool=False)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the difference between `.show` and `.head`?\n",
    "    - .show displays a table \n",
    "    - .head displays row by row\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - View a summary of the data using `.describe`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+\n",
      "|summary|                 n|group|\n",
      "+-------+------------------+-----+\n",
      "|  count|                20|   20|\n",
      "|   mean|0.3664026449885217| null|\n",
      "| stddev|0.8905322898155363| null|\n",
      "|    min|-1.261605945319069|    x|\n",
      "|    max|2.1503829673811126|    z|\n",
      "+-------+------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Use `.select` to create a new dataframe with just the `n` and `abool` columns. View the first 5 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(n=-0.712390662050588, abool=False),\n",
       " Row(n=0.753766378659703, abool=False),\n",
       " Row(n=-0.044503078338053455, abool=False),\n",
       " Row(n=0.45181233874578974, abool=False),\n",
       " Row(n=1.3451017084510097, abool=False)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(df.n, df.abool).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Use `.select` to create a new dataframe with just the `group` and `abool` columns. View the first 5 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|group|abool|\n",
      "+-----+-----+\n",
      "|    z|false|\n",
      "|    x|false|\n",
      "|    z|false|\n",
      "|    y|false|\n",
      "|    z|false|\n",
      "+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('group', 'abool').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Use `.select` to create a new dataframe with the `group` column and the `abool` column renamed to `a_boolean_value`. Show the first 3 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "|group|a_boolean_value|\n",
      "+-----+---------------+\n",
      "|    z|          false|\n",
      "|    x|          false|\n",
      "|    z|          false|\n",
      "+-----+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('group', df.abool.alias('a_boolean_value')).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Use `.select` to create a new dataframe with the `group` column and the `n` column renamed to `a_numeric_value`. Show the first 6 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|group|     a_numeric_value|\n",
      "+-----+--------------------+\n",
      "|    z|  -0.712390662050588|\n",
      "|    x|   0.753766378659703|\n",
      "|    z|-0.04450307833805...|\n",
      "|    y| 0.45181233874578974|\n",
      "|    z|  1.3451017084510097|\n",
      "|    y|  0.5323378882945463|\n",
      "+-----+--------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.group, df.n.alias('a_numeric_value')).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Column Manipulation\n",
    "\n",
    "   - Use the starter code above to re-create a spark dataframe. Store the spark dataframe in a varaible named `df`\n",
    "   - Use `.select` to add 4 to the `n` column. Show the results.\n",
    "   - Subtract 5 from the `n` column and view the results.\n",
    "   - Multiply the `n` column by 2. View the results along with the original numbers.\n",
    "   - Add a new column named `n2` that is the `n` value multiplied by -1. Show the first 4 rows of your dataframe. You should see the original `n` value as well as `n2`.\n",
    "   - Add a new column named `n3` that is the n value squared. Show the first 5 rows of your dataframe. You should see both `n`, `n2`, and `n3`.\n",
    "   - What happens when you run the code below?\n",
    "\n",
    "        ```python\n",
    "        df.group + df.abool\n",
    "        ```\n",
    "   - What happens when you run the code below? What is the difference between this and the previous code sample?\n",
    "        ```python\n",
    "        df.select(df.group + df.abool)\n",
    "        ```\n",
    "   - Try adding various other columns together. What are the results of combining the different data types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_dataframe = pd.DataFrame(\n",
    "    {\n",
    "        \"n\": np.random.randn(20),\n",
    "        \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "        \"abool\": np.random.choice([True, False], 20),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[n: double, group: string, abool: boolean]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|           (n + 4)|\n",
      "+------------------+\n",
      "|3.1149379007131692|\n",
      "| 4.072726746112778|\n",
      "|  3.17248089880026|\n",
      "| 3.408449078116781|\n",
      "|1.8137843744202362|\n",
      "| 2.569549639183047|\n",
      "| 4.001182616633274|\n",
      "|3.8475812944997965|\n",
      "| 5.441801039148292|\n",
      "|3.8150782574916233|\n",
      "|3.7701022385474636|\n",
      "|3.7366226992400553|\n",
      "| 3.917137758688362|\n",
      "| 3.614943119975514|\n",
      "| 3.898948828237532|\n",
      "|   4.3311542231059|\n",
      "| 4.043299425816474|\n",
      "|3.5500234639915056|\n",
      "| 4.347198137446713|\n",
      "| 5.459100088619229|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n + 4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Subtract 5 from the `n` column and view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|            (n - 5)|\n",
      "+-------------------+\n",
      "| -5.885062099286831|\n",
      "| -4.927273253887222|\n",
      "|  -5.82751910119974|\n",
      "| -5.591550921883219|\n",
      "| -7.186215625579764|\n",
      "| -6.430450360816954|\n",
      "| -4.998817383366726|\n",
      "| -5.152418705500204|\n",
      "| -3.558198960851709|\n",
      "| -5.184921742508377|\n",
      "| -5.229897761452537|\n",
      "| -5.263377300759944|\n",
      "| -5.082862241311638|\n",
      "| -5.385056880024486|\n",
      "| -5.101051171762468|\n",
      "|   -4.6688457768941|\n",
      "| -4.956700574183526|\n",
      "| -5.449976536008494|\n",
      "| -4.652801862553287|\n",
      "|-3.5408999113807718|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n -5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Multiply the `n` column by 2. View the results along with the original numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                   n|             (n * 2)|\n",
      "+--------------------+--------------------+\n",
      "| -0.8850620992868307| -1.7701241985736613|\n",
      "| 0.07272674611277782| 0.14545349222555565|\n",
      "|   -0.82751910119974|   -1.65503820239948|\n",
      "|  -0.591550921883219|  -1.183101843766438|\n",
      "|  -2.186215625579764|  -4.372431251159528|\n",
      "| -1.4304503608169532| -2.8609007216339064|\n",
      "|0.001182616633274...|0.002365233266549...|\n",
      "|-0.15241870550020373|-0.30483741100040745|\n",
      "|  1.4418010391482912|  2.8836020782965823|\n",
      "|-0.18492174250837645| -0.3698434850167529|\n",
      "| -0.2298977614525365|  -0.459795522905073|\n",
      "| -0.2633773007599446| -0.5267546015198892|\n",
      "|-0.08286224131163808|-0.16572448262327616|\n",
      "|-0.38505688002448574| -0.7701137600489715|\n",
      "|-0.10105117176246801|-0.20210234352493603|\n",
      "| 0.33115422310589987|  0.6623084462117997|\n",
      "| 0.04329942581647413| 0.08659885163294825|\n",
      "|-0.44997653600849435| -0.8999530720169887|\n",
      "|  0.3471981374467132|  0.6943962748934264|\n",
      "|  1.4591000886192282|  2.9182001772384565|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n, df.n * 2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      - Add a new column named `n2` that is the `n` value multiplied by -1. Show the first 4 rows of your dataframe. You should see the original `n` value as well as `n2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|                  n|                  n2|\n",
      "+-------------------+--------------------+\n",
      "|-0.8850620992868307|  0.8850620992868307|\n",
      "|0.07272674611277782|-0.07272674611277782|\n",
      "|  -0.82751910119974|    0.82751910119974|\n",
      "| -0.591550921883219|   0.591550921883219|\n",
      "+-------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n, (df.n * (-1)).alias('n2')).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Add a new column named `n3` that is the n value squared. Show the first 5 rows of your dataframe. You should see both `n`, `n2`, and `n3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+\n",
      "|                  n|                  n2|                  n3|\n",
      "+-------------------+--------------------+--------------------+\n",
      "|-0.8850620992868307|  0.8850620992868307|  0.7833349195940117|\n",
      "|0.07272674611277782|-0.07272674611277782|0.005289179600152444|\n",
      "|  -0.82751910119974|    0.82751910119974|  0.6847878628504256|\n",
      "| -0.591550921883219|   0.591550921883219| 0.34993249318088626|\n",
      "| -2.186215625579764|   2.186215625579764|   4.779538761529118|\n",
      "+-------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n, (df.n * (-1)).alias('n2'), (df.n * df.n).alias('n3')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - What happens when you run the code below?\n",
    "\n",
    "        ```python\n",
    "        df.group + df.abool\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(group + abool)'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.group + df.abool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   - What happens when you run the code below? What is the difference between\n",
    "       this and the previous code sample?\n",
    "\n",
    "        ```python\n",
    "        df.select(df.group + df.abool)\n",
    "        ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '(CAST(group AS DOUBLE) + abool)' due to data type mismatch: differing types in '(CAST(group AS DOUBLE) + abool)' (double and boolean).;\n'Project [unresolvedalias((cast(group#358 as double) + abool#359), Some(org.apache.spark.sql.Column$$Lambda$3425/0x0000000801412040@64eb4466))]\n+- LogicalRDD [n#357, group#358, abool#359], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_v/lfgsfb3n229bdhyjm1pj7f840000gn/T/ipykernel_57957/2226179756.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \"\"\"\n\u001b[0;32m-> 1685\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '(CAST(group AS DOUBLE) + abool)' due to data type mismatch: differing types in '(CAST(group AS DOUBLE) + abool)' (double and boolean).;\n'Project [unresolvedalias((cast(group#358 as double) + abool#359), Some(org.apache.spark.sql.Column$$Lambda$3425/0x0000000801412040@64eb4466))]\n+- LogicalRDD [n#357, group#358, abool#359], false\n"
     ]
    }
   ],
   "source": [
    "df.select(df.group + df.abool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   - Try adding various other columns together. What are the results of\n",
    "       combining the different data types?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Type casting\n",
    "\n",
    "    1. Use the starter code above to re-create a spark dataframe.\n",
    "\n",
    "    1. Use `.printSchema` to view the datatypes in your dataframe.\n",
    "\n",
    "    1. Use `.dtypes` to view the datatypes in your dataframe.\n",
    "\n",
    "    1. What is the difference between the two code samples below?\n",
    "\n",
    "        ```python\n",
    "        df.abool.cast('int')\n",
    "        ```\n",
    "\n",
    "        ```python\n",
    "        df.select(df.abool.cast('int')).show()\n",
    "        ```\n",
    "\n",
    "    1. Use `.select` and `.cast` to convert the `abool` column to an integer\n",
    "       type. View the results.\n",
    "    1. Convert the `group` column to a integer data type and view the results.\n",
    "       What happens?\n",
    "    1. Convert the `n` column to a integer data type and view the results. What\n",
    "       happens?\n",
    "    1. Convert the `abool` column to a string data type and view the results.\n",
    "       What happens?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[n: double, group: string, abool: boolean]>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', 'double'), ('group', 'string'), ('abool', 'boolean')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'CAST(abool AS INT)'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.abool.cast('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|abool|\n",
      "+-----+\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    0|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    1|\n",
      "|    1|\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    1|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.abool.cast('int')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|group|\n",
      "+-----+\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.group.cast('int')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|abool|\n",
      "+-----+\n",
      "|false|\n",
      "| true|\n",
      "|false|\n",
      "|false|\n",
      "| true|\n",
      "| true|\n",
      "| true|\n",
      "| true|\n",
      "|false|\n",
      "| true|\n",
      "|false|\n",
      "| true|\n",
      "| true|\n",
      "|false|\n",
      "| true|\n",
      "|false|\n",
      "|false|\n",
      "| true|\n",
      "|false|\n",
      "| true|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.abool.cast('string')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Built-in Functions\n",
    "\n",
    "    1. Use the starter code above to re-create a spark dataframe.\n",
    "    1. Import the necessary functions from `pyspark.sql.functions`\n",
    "    1. Find the highest `n` value.\n",
    "    1. Find the lowest `n` value.\n",
    "    1. Find the average `n` value.\n",
    "    1. Use `concat` to change the `group` column to say, e.g. \"Group: x\" or\n",
    "       \"Group: y\"\n",
    "    1. Use `concat` to combine the `n` and `group` columns to produce results\n",
    "       that look like this: \"x: -1.432\" or \"z: 2.352\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, sum, avg, min, max, count, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+--------------------+--------------------+\n",
      "|            max(n)|            min(n)|              avg(n)|              avg(n)|\n",
      "+------------------+------------------+--------------------+--------------------+\n",
      "|1.4591000886192282|-2.186215625579764|-0.20369490856059969|-0.20369490856059969|\n",
      "+------------------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/19 20:15:09 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 907676 ms exceeds timeout 120000 ms\n",
      "22/05/19 20:15:09 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    max(df.n),\n",
    "    min(df.n),\n",
    "    avg(df.n),\n",
    "    mean(df.n)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5. When / Otherwise\n",
    "\n",
    "    1. Use the starter code above to re-create a spark dataframe.\n",
    "    1. Use `when` and `.otherwise` to create a column that contains the text \"It\n",
    "       is true\" when `abool` is true and \"It is false\"\" when `abool` is false.\n",
    "    1. Create a column that contains 0 if n is less than 0, otherwise, the\n",
    "       original n value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Filter / Where\n",
    "\n",
    "    1. Use the starter code above to re-create a spark dataframe.\n",
    "    1. Use `.filter` or `.where` to select just the rows where the group is `y`\n",
    "       and view the results.\n",
    "    1. Select just the columns where the `abool` column is false and view the\n",
    "       results.\n",
    "    1. Find the columns where the `group` column is *not* `y`.\n",
    "    1. Find the columns where `n` is positive.\n",
    "    1. Find the columns where `abool` is true and the `group` column is `z`.\n",
    "    1. Find the columns where `abool` is true or the `group` column is `z`.\n",
    "    1. Find the columns where `abool` is false and `n` is less than 1\n",
    "    1. Find the columns where `abool` is false or `n` is less than 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Sorting\n",
    "\n",
    "    1. Use the starter code above to re-create a spark dataframe.\n",
    "    1. Sort by the `n` value.\n",
    "    1. Sort by the `group` value, both ascending and descending.\n",
    "    1. Sort by the group value first, then, within each group, sort by `n`\n",
    "       value.\n",
    "    1. Sort by `abool`, `group`, and `n`. Does it matter in what order you\n",
    "       specify the columns when sorting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "8. Aggregating\n",
    "\n",
    "    1. What is the average `n` value for each group in the `group` column?\n",
    "    1. What is the maximum `n` value for each group in the `group` column?\n",
    "    1. What is the minimum `n` value by `abool`?\n",
    "    1. What is the average `n` value for each unique combination of the `group`\n",
    "       and `abool` column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "9. Spark SQL\n",
    "\n",
    "    1. Use the starter code above to re-create a spark dataframe.\n",
    "    1. Turn your dataframe into a table that can be queried with spark SQL. Name\n",
    "       the table `my_df`. Answer the rest of the questions in this section with\n",
    "       a spark sql query (`spark.sql`) against `my_df`. After each step, view\n",
    "       the first 7 records from the dataframe.\n",
    "    1. What happens if you make a SQL syntax error in your query?\n",
    "    1. Write a query that shows all of the columns from your dataframe.\n",
    "    1. Write a query that shows just the `n` and `abool` columns from the\n",
    "       dataframe.\n",
    "    1. Write a query that shows just the `n` and `group` columns. Rename the\n",
    "       `group` column to `g`.\n",
    "    1. Write a query that selects `n`, and creates two new columns: `n2`, the\n",
    "       original `n` values halved, and `n3`: the original n values minus 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
