{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/19 15:06:53 WARN Utils: Your hostname, Abdiels-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.96 instead (on interface en0)\n",
      "22/05/19 15:06:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/19 15:06:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "    - The name of the column should be language\n",
    "    - View the schema of the dataframe\n",
    "    - Output the shape of the dataframe\n",
    "    - Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \n",
    "pandas_df = pd.DataFrame({'language':['python', 'mysql', 'html', 'c++', 'css', 'java']})\n",
    "\n",
    "df = spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the Schema of the dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=====>                                                    (1 + 9) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# output the shape\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  python|\n",
      "|   mysql|\n",
      "|    html|\n",
      "|     c++|\n",
      "|     css|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the first 5 records \n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "    - a. Create 1 column of output that contains a message like the one below:\n",
    "        > The 1999 audi a4 has a 4 cylinder engine.\n",
    "    \n",
    "        For each vehicle.\n",
    "\n",
    "    - b. Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import data function\n",
    "from pydataset import data\n",
    "# assign the data to a variable\n",
    "mpg = spark.createDataFrame(data('mpg'))\n",
    "# ensure it worked\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+\n",
      "|Description                                                   |\n",
      "+--------------------------------------------------------------+\n",
      "|The 1999 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 6 cylinder engine.                     |\n",
      "|The 1999 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 1999 audi a6 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a 8 cylinder engine.             |\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8 cylinder engine.|\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8 cylinder engine.|\n",
      "+--------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import pyspark functions\n",
    "from pyspark.sql.functions import concat, lit, sum, avg, min, max, count, mean, when\n",
    "\n",
    "# Create a column that contains message like listed above for each vehicle\n",
    "mpg.select(\n",
    "    concat(lit(\"The \"), \n",
    "    mpg.year,lit(' '), \n",
    "    mpg.manufacturer, lit(' '),  \n",
    "    mpg.model, lit(' has a '), \n",
    "    mpg.cyl, lit(' cylinder engine.')\n",
    "    ).alias('Description')\n",
    ").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Transmision|\n",
      "+-----------+\n",
      "|automatic  |\n",
      "|manual     |\n",
      "|manual     |\n",
      "|automatic  |\n",
      "|automatic  |\n",
      "|manual     |\n",
      "|automatic  |\n",
      "|manual     |\n",
      "|automatic  |\n",
      "|manual     |\n",
      "|automatic  |\n",
      "|automatic  |\n",
      "|manual     |\n",
      "|automatic  |\n",
      "|manual     |\n",
      "|automatic  |\n",
      "|automatic  |\n",
      "|automatic  |\n",
      "|automatic  |\n",
      "|automatic  |\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import when\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Transform the trans column so that it only contains either manual or auto\n",
    "mpg.select(\n",
    "    when(\n",
    "        mpg.trans.like('manual%'), 'manual')\n",
    "        .otherwise('automatic')\n",
    "        .alias('Transmision')\n",
    "    ).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "    - a. What percentage of observations are smokers?\n",
    "    - b. Create a column that contains the tip percentage\n",
    "    - c. Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the tips dataset as a spark dataframe.\n",
    "tips = spark.createDataFrame(data('tips'))\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------+\n",
      "|smoker|count|percent|\n",
      "+------+-----+-------+\n",
      "|    No|  151|  61.89|\n",
      "|   Yes|   93|  38.11|\n",
      "+------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import col and round\n",
    "from pyspark.sql.functions import col, round\n",
    "\n",
    "# What percentage of observations are smokers? \n",
    "# ====> 38.11%\n",
    "tips.groupBy('smoker').count().withColumn('percent', \n",
    "    (round((col('count')/tips.count()*100), 2))\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|tip_percentage (%)|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|              5.94|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|             16.05|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|             16.66|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|             13.98|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|             14.68|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|             18.62|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|             22.81|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|             11.61|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|             13.03|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|             21.85|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|             16.65|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|             14.18|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|             10.18|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|             16.28|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|             20.36|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|             18.16|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|             16.17|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|             22.77|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|             20.62|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|             16.22|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a column that contains the tip percentage\n",
    "tips.withColumn(\"tip_percentage (%)\", round(col(\"tip\") / col(\"total_bill\")*100, 2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+\n",
      "|   sex|   No|  Yes|\n",
      "+------+-----+-----+\n",
      "|Female|15.69|18.21|\n",
      "|  Male|16.07|15.28|\n",
      "+------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average tip percentage for each combination of sex and smoker.\n",
    "(\n",
    "    tips.withColumn(\"tip_percentage\", round(col(\"tip\") / col(\"total_bill\")*100,2))\n",
    "    .groupby(\"sex\")\n",
    "    .pivot(\"smoker\")\n",
    "    .agg(round(mean(\"tip_percentage\"), 2))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "    - Convert the temperatures to fahrenheit.\n",
    "    - Which month has the most rain, on average?\n",
    "    - Which year was the windiest?\n",
    "    - What is the most frequent type of weather in January?\n",
    "    - What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "    - What percentage of days were rainy in q3 of 2015?\n",
    "    - For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import data \n",
    "from vega_datasets import data\n",
    "\n",
    "weather = spark.createDataFrame(data.seattle_weather())\n",
    "weather.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|   55.04|    41.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|   51.08|   37.04| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|   53.06|   44.96| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|   53.96|   42.08| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|   48.02|   37.04| 6.1|   rain|\n",
      "|2012-01-06 00:00:00|          2.5|   39.92|   35.96| 2.2|   rain|\n",
      "|2012-01-07 00:00:00|          0.0|   44.96|   37.04| 2.3|   rain|\n",
      "|2012-01-08 00:00:00|          0.0|    50.0|   37.04| 2.0|    sun|\n",
      "|2012-01-09 00:00:00|          4.3|   48.92|    41.0| 3.4|   rain|\n",
      "|2012-01-10 00:00:00|          1.0|   42.98|   33.08| 3.4|   rain|\n",
      "|2012-01-11 00:00:00|          0.0|   42.98|   30.02| 5.1|    sun|\n",
      "|2012-01-12 00:00:00|          0.0|   42.98|   28.94| 1.9|    sun|\n",
      "|2012-01-13 00:00:00|          0.0|    41.0|   26.96| 1.3|    sun|\n",
      "|2012-01-14 00:00:00|          4.1|   39.92|   33.08| 5.3|   snow|\n",
      "|2012-01-15 00:00:00|          5.3|   33.98|   26.06| 3.2|   snow|\n",
      "|2012-01-16 00:00:00|          2.5|   35.06|   26.96| 5.0|   snow|\n",
      "|2012-01-17 00:00:00|          8.1|   37.94|    32.0| 5.6|   snow|\n",
      "|2012-01-18 00:00:00|         19.8|    32.0|   26.96| 5.0|   snow|\n",
      "|2012-01-19 00:00:00|         15.2|   30.02|   26.96| 1.6|   snow|\n",
      "|2012-01-20 00:00:00|         13.5|   44.96|   30.02| 2.3|   snow|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the temperatures to fahrenheit\n",
    "# F = C * 1.8 + 32\n",
    "weather.withColumn(\n",
    "    \"temp_max\", round((col(\"temp_max\") * 1.8 + 32),2)\n",
    ").withColumn(\"temp_min\", round((col(\"temp_min\") * 1.8 + 32), 2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(month=11, avg_monthly_rain=160.625)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add pyspark month, year, and quarter function\n",
    "from pyspark.sql.functions import month, year, quarter\n",
    "\n",
    "# Which month has the most rain, on average?\n",
    "(\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"month\", \"year\")\n",
    "    .agg(sum(\"precipitation\").alias(\"total_monthly_precipitation\"))\n",
    "    .groupBy(\"month\")\n",
    "    .agg(mean(\"total_monthly_precipitation\").alias(\"avg_monthly_rain\"))\n",
    "    .sort(col(\"avg_monthly_rain\").desc())\n",
    "    .first()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(year=2012, total_winds=3.4)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which year was the windiest?\n",
    "(\n",
    "    weather.withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"year\")\n",
    "    .agg(round(mean(\"wind\"),2).alias(\"total_winds\"))\n",
    "    .sort(col(\"total_winds\").desc())\n",
    "    .first()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(weather='fog', count=38)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the most frequent type of weather in January?\n",
    "(\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .filter(col(\"month\") == 1)\n",
    "    .groupBy(\"weather\")\n",
    "    .count()\n",
    "    .sort(col(\"count\").desc())\n",
    "    .first()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+\n",
      "|average_high_temp|average_low_temp|\n",
      "+-----------------+----------------+\n",
      "|            26.83|           14.18|\n",
      "+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "(\n",
    "    weather.filter(month(\"date\") == 7)\n",
    "    .filter(year(\"date\") > 2012)\n",
    "    .filter(year(\"date\") < 2015)\n",
    "    .filter(col(\"weather\") == lit(\"sun\"))\n",
    "    .agg(\n",
    "        round(avg(\"temp_max\"),2).alias(\"average_high_temp\"),\n",
    "        round(avg(\"temp_min\"),2).alias(\"average_low_temp\"),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg rain|\n",
      "+--------+\n",
      "|  0.0217|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What percentage of days were rainy in q3 of 2015?\n",
    "(\n",
    "    weather.filter(year(\"date\") == 2015)\n",
    "    .filter(quarter(\"date\") == 3)\n",
    "    .select(when(col(\"weather\") == \"rain\", 1).otherwise(0).alias(\"rain\"))\n",
    "    .agg(round(mean(\"rain\"),4).alias('avg rain'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|year|avg rain|\n",
      "+----+--------+\n",
      "|2012|  0.4836|\n",
      "|2013|  0.4164|\n",
      "|2014|   0.411|\n",
      "|2015|  0.3945|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each year, find what percentage of days it rained (had non-zero precipitation)\n",
    "(\n",
    "    weather.withColumn(\"year\", year(\"date\"))\n",
    "    .select(when(col(\"precipitation\") > 0, 1).otherwise(0).alias(\"did_rain\"), \"year\")\n",
    "    .groupby(\"year\")\n",
    "    .agg(round(mean(\"did_rain\"), 4).alias('avg rain'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
